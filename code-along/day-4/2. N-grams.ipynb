{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d13d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import \n",
    "import \n",
    "\n",
    "from nltk.util import \n",
    "from sklearn.feature_extraction.text import \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2843590",
   "metadata": {},
   "source": [
    "### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ((data), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    " \n",
    "data = 'A class is a blueprint for the object.'\n",
    " \n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))\n",
    "print(\"4-gram: \", extract_ngrams(data, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('twitter_training.csv', header=None, usecols=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31805105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview of dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b47884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.columns = ['Sentiment', 'Text']\n",
    "\n",
    "# remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# encode target label\n",
    "le = LabelEncoder()\n",
    "df['Sentiment'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# establish input and output\n",
    "X = list(df['Text'])\n",
    "y = list(df['Sentiment'])\n",
    "\n",
    "# split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7699e",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c87271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bag of words for with unigrams and bigrams\n",
    "cv = (analyzer = 'word',ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "# convert training data to bag of words\n",
    "X_train_cv = cv.(X_train)\n",
    "X_test_cv = cv.(X_test)\n",
    "\n",
    "# train naive bayes classifier\n",
    "clf = ()\n",
    "clf.(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf.(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe86683",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bag of words for with unigrams and bigrams\n",
    "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "# convert training data to bag of words\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "# train naive bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='micro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in range(1,11):\n",
    "    \n",
    "    # convert training data to bag of words\n",
    "    cv = CountVectorizer(analyzer = 'word',ngram_range=(1,N), stop_words='english')\n",
    "    X_train_cv = cv.fit_transform(X_train)\n",
    "    X_test_cv = cv.transform(X_test)\n",
    "    \n",
    "    # train model and generate predictions\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_cv, y_train)\n",
    "    y_pred = clf.predict(X_test_cv)\n",
    "    \n",
    "    # compute f-1 score\n",
    "    score = np.round(f1_score(y_test, y_pred, average='micro'), 4)\n",
    "    print('F-1 score of model with n-gram range of {}: {}'.format((1,N), score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
